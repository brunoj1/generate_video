{
  "6": {
    "inputs": {
      "text": [
        "246",
        0
      ],
      "clip": [
        "228",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": [
        "247",
        0
      ],
      "clip": [
        "228",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "226": {
    "inputs": {
      "vae_name": "wan2.2_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "VAE Load"
    }
  },
  "228": {
    "inputs": {
      "clip_name": "umt5_xxl_fp16.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "CLIP Load"
    }
  },
  "230": {
    "inputs": {
      "unet_name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Diffusion Model Load"
    }
  },
  "235": {
    "inputs": {
      "unet_name": "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Diffusion Model Load"
    }
  },
  "246": {
    "inputs": {
      "value": "prompt"
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "Positive Prompt (STRING)"
    }
  },
  "247": {
    "inputs": {
      "value": "Avoid unrealistic lighting, distorted proportions, or cluttered overlays. Do not include unrelated furniture styles, outdoor scenes, or abstract visual effects. Exclude jump cuts, shaky camera movements, or narrow angles that obscure parts of the room. Do not alter the original design aesthetic or introduce elements not present in the attached image."
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "Negative Prompt (STRING)"
    }
  },
  "260": {
    "inputs": {
      "image": "ComfyUI_34777_.png"
    },
    "class_type": "ETN_LoadImageBase64",
    "_meta": {
      "title": "Image Load"
    }
  },
   "261": {
    "inputs": {
      "image": "ComfyUI_34777_.png"
    },
    "class_type": "ETN_LoadImageBase64",
    "_meta": {
      "title": "Image Load"
    }
  },
  "277": {
    "inputs": {
      "frame_rate": 16,
      "loop_count": 0,
      "filename_prefix": "25-09-10/wan/25-09-10-FASTWAN",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 15,
      "save_metadata": true,
      "trim_to_audio": true,
      "pingpong": false,
      "save_output": true,
      "images": [
        "323",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢"
    }
  },
  "283": {
    "inputs": {
      "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_HIGH_fp16.safetensors",
      "strength_model": 0.4,
      "model": [
        "230",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoRA Load (Model Only)"
    }
  },
  "284": {
    "inputs": {
      "lora_name": "Wan2.2-Lightning_I2V-A14B-4steps-lora_LOW_fp16.safetensors",
      "strength_model": 1,
      "model": [
        "235",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoRA Load (Model Only)"
    }
  },
  "285": {
    "inputs": {
      "lora_name": "Wan21_CausVid_14B_T2V_lora_rank32.safetensors",
      "strength_model": 0.4,
      "model": [
        "284",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoRA Load (Model Only)"
    }
  },
  "288": {
    "inputs": {
      "model": [
        "594",
        0
      ]
    },
    "class_type": "ModelPassThrough",
    "_meta": {
      "title": "ModelPass"
    }
  },
  "290": {
    "inputs": {
      "model": [
        "593",
        0
      ]
    },
    "class_type": "ModelPassThrough",
    "_meta": {
      "title": "ModelPass"
    }
  },
  "323": {
    "inputs": {
      "samples": [
        "832",
        0
      ],
      "vae": [
        "226",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "362": {
    "inputs": {
      "shift": 8.000000000000002,
      "model": [
        "288",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "Model Sampling (SD3)"
    }
  },
  "363": {
    "inputs": {
      "shift": 8.000000000000002,
      "model": [
        "290",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "Model Sampling (SD3)"
    }
  },
  "377": {
    "inputs": {
      "empty_cache": true,
      "gc_collect": true,
      "unload_all_models": true,
      "any_input": [
        "277",
        0
      ]
    },
    "class_type": "VRAM_Debug",
    "_meta": {
      "title": "VRAM Debug"
    }
  },
  "378": {
    "inputs": {
      "any_input": [
        "377",
        0
      ]
    },
    "class_type": "DummyOut",
    "_meta": {
      "title": "Dummy Out"
    }
  },
  "390": {
    "inputs": {
      "backend": "inductor",
      "fullgraph": false,
      "mode": "default",
      "dynamic": false,
      "compile_transformer_blocks_only": true,
      "dynamo_cache_size_limit": 64,
      "model": [
        "285",
        0
      ]
    },
    "class_type": "TorchCompileModelWanVideoV2",
    "_meta": {
      "title": "TorchCompileModelWanVideoV2"
    }
  },
  "391": {
    "inputs": {
      "backend": "inductor",
      "fullgraph": false,
      "mode": "default",
      "dynamic": false,
      "compile_transformer_blocks_only": true,
      "dynamo_cache_size_limit": 64,
      "model": [
        "283",
        0
      ]
    },
    "class_type": "TorchCompileModelWanVideoV2",
    "_meta": {
      "title": "TorchCompileModelWanVideoV2"
    }
  },
  "392": {
    "inputs": {
      "sage_attention": "sageattn_qk_int8_pv_fp8_cuda++",
      "model": [
        "391",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "393": {
    "inputs": {
      "sage_attention": "sageattn_qk_int8_pv_fp8_cuda++",
      "model": [
        "390",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "481": {
    "inputs": {
      "width": [
        "845",
        0
      ],
      "height": [
        "845",
        1
      ],
      "length": [
        "846",
        0
      ],
      "batch_size": 1,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "vae": [
        "226",
        0
      ],
      "start_image": [
        "847",
        0
      ],
      "end_image": [
        "860",
        0
      ]
    },
    "class_type": "WanFirstLastFrameToVideo",
    "_meta": {
      "title": "WAN Video Generation (Start-End Frame)"
    }
  },
  "593": {
    "inputs": {
      "reuse_threshold": 0.2,
      "start_percent": 0.15,
      "end_percent": 0.95,
      "verbose": false,
      "model": [
        "392",
        0
      ]
    },
    "class_type": "EasyCache",
    "_meta": {
      "title": "EasyCache"
    }
  },
  "594": {
    "inputs": {
      "reuse_threshold": 0.2,
      "start_percent": 0.15,
      "end_percent": 0.95,
      "verbose": false,
      "model": [
        "393",
        0
      ]
    },
    "class_type": "EasyCache",
    "_meta": {
      "title": "EasyCache"
    }
  },
  "828": {
    "inputs": {},
    "class_type": "DisableNoise",
    "_meta": {
      "title": "Disable Noise"
    }
  },
  "829": {
    "inputs": {
      "step": 6,
      "sigmas": [
        "834",
        0
      ]
    },
    "class_type": "SplitSigmas",
    "_meta": {
      "title": "Split Sigmas Array (Step)"
    }
  },
  "830": {
    "inputs": {
      "cfg": 4,
      "start_percent": 0,
      "end_percent": 0.33,
      "model": [
        "363",
        0
      ],
      "positive": [
        "481",
        0
      ],
      "negative": [
        "481",
        1
      ]
    },
    "class_type": "ScheduledCFGGuidance",
    "_meta": {
      "title": "Scheduled CFG Guidance"
    }
  },
  "831": {
    "inputs": {
      "sampler_name": "ddim"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSampler (Select)"
    }
  },
  "832": {
    "inputs": {
      "noise": [
        "828",
        0
      ],
      "guider": [
        "833",
        0
      ],
      "sampler": [
        "831",
        0
      ],
      "sigmas": [
        "829",
        1
      ],
      "latent_image": [
        "836",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "LowNoiseSampler"
    }
  },
  "833": {
    "inputs": {
      "model": [
        "362",
        0
      ],
      "conditioning": [
        "481",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "Basic Guider"
    }
  },
  "834": {
    "inputs": {
      "steps": 10,
      "alpha": 0.7,
      "beta": 0.55,
      "model": [
        "363",
        0
      ]
    },
    "class_type": "BetaSamplingScheduler",
    "_meta": {
      "title": "Beta Sampling Scheduler"
    }
  },
  "835": {
    "inputs": {
      "noise_seed": 2508300001
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "Random Noise"
    }
  },
  "836": {
    "inputs": {
      "noise": [
        "835",
        0
      ],
      "guider": [
        "830",
        0
      ],
      "sampler": [
        "831",
        0
      ],
      "sigmas": [
        "829",
        0
      ],
      "latent_image": [
        "481",
        2
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "HighNoiseSampler"
    }
  },
  "837": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": [
        "840",
        0
      ],
      "image": [
        "841",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Image Scale By"
    }
  },
  "838": {
    "inputs": {
      "value": 16
    },
    "class_type": "FloatConstant",
    "_meta": {
      "title": "Float Constant"
    }
  },
  "839": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": [
        "838",
        0
      ],
      "image": [
        "837",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Image Scale By"
    }
  },
  "840": {
    "inputs": {
      "value": 0.0625
    },
    "class_type": "FloatConstant",
    "_meta": {
      "title": "Float Constant"
    }
  },
  "841": {
    "inputs": {
      "width": [
        "849",
        0
      ],
      "height": [
        "848",
        0
      ],
      "batch_size": 1,
      "color": 0
    },
    "class_type": "EmptyImage",
    "_meta": {
      "title": "Empty Image"
    }
  },
  "842": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": [
        "852",
        0
      ],
      "image": [
        "839",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Image Scale By"
    }
  },
  "843": {
    "inputs": {
      "image": [
        "842",
        0
      ]
    },
    "class_type": "GetImageSize",
    "_meta": {
      "title": "Get Image Size"
    }
  },
  "845": {
    "inputs": {
      "image": [
        "839",
        0
      ]
    },
    "class_type": "GetImageSize",
    "_meta": {
      "title": "Get Image Size"
    }
  },
  "846": {
    "inputs": {
      "value": 81
    },
    "class_type": "INTConstant",
    "_meta": {
      "title": "LENGTH"
    }
  },
  "847": {
    "inputs": {
      "upscale_method": "lanczos",
      "width": [
        "843",
        0
      ],
      "height": [
        "843",
        1
      ],
      "crop": "center",
      "image": [
        "260",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image - F"
    }
  },
   "860": {
    "inputs": {
      "upscale_method": "lanczos",
      "width": [
        "843",
        0
      ],
      "height": [
        "843",
        1
      ],
      "crop": "center",
      "image": [
        "261",
        0
      ]
    },
    "class_type": "ImageScale",
    "_meta": {
      "title": "Upscale Image - F"
    }
  },
  "848": {
    "inputs": {
      "value": 768
    },
    "class_type": "INTConstant",
    "_meta": {
      "title": "HEIGHT"
    }
  },
  "849": {
    "inputs": {
      "value": 512
    },
    "class_type": "INTConstant",
    "_meta": {
      "title": "WIDTH"
    }
  },
  "852": {
    "inputs": {
      "value": 2
    },
    "class_type": "PrimitiveFloat",
    "_meta": {
      "title": "Scale Factor"
    }
  }
}